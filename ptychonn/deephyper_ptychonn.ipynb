{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84e25e-a0da-48c4-8dc6-119237100ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import json\n",
    "import torch, argparse, os, time, sys, shutil, logging\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "from numpy.fft import fftn, fftshift\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import MaxPool2d, ReLU, Linear, Upsample\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import biotorch\n",
    "from math import log\n",
    "\n",
    "from deephyper.problem import HpProblem\n",
    "from deephyper.search.hps import CBO\n",
    "from deephyper.evaluator import Evaluator\n",
    "from deephyper.evaluator.callback import TqdmCallback\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff86d98-8f2c-4544-88be-318fe937d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "numIterations = 100\n",
    "\n",
    "#adding a parseable parameter for training algorithm. \n",
    "parser = argparse.ArgumentParser(description='PtychoNN.')\n",
    "parser.add_argument('-train_alg',type=str, default=\"BP\")\n",
    "\n",
    "args, unparsed = parser.parse_known_args()\n",
    "\n",
    "# learning algorithms supported in this experiment. \n",
    "if args.train_alg==\"BP\":\n",
    "    from torch.nn import Conv2d\n",
    "elif args.train_alg==\"fa\":\n",
    "    from biotorch.layers.fa import Conv2d\n",
    "elif args.train_alg==\"dfa\":\n",
    "    from biotorch.layers.dfa import Conv2d\n",
    "elif args.train_alg==\"usf\":\n",
    "    from biotorch.layers.usf import Conv2d\n",
    "elif args.train_alg==\"frsf\":\n",
    "    from biotorch.layers.frsf import Conv2d\n",
    "elif args.train_alg==\"brsf\":\n",
    "    from biotorch.layers.brsf import Conv2d\n",
    "else :\n",
    "    print(train_alg, 'is not supported')\n",
    "\n",
    "#epochs = 60\n",
    "\n",
    "batch = 64\n",
    "\n",
    "\n",
    "h,w = 64,64\n",
    "nlines = 100 #How many lines of data to use for training?\n",
    "nltest = 60 #How many lines for the test set?\n",
    "\n",
    "n_valid = 805 #How much to reserve for validation\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "#nconv = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac54acc-d6c0-4c6d-a03c-9b08c033514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertConv(layers, depth, in_channels, out_channels):\n",
    "    layers.append(Conv2d(in_channels, out_channels, 3, stride=1, padding=(1,1)))\n",
    "    layers.append(torch.nn.ReLU())\n",
    "    for i in range(depth-1):\n",
    "        layers.append(Conv2d(out_channels, out_channels, 3, stride=1, padding=(1,1)))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "    \n",
    "    return layers \n",
    "\n",
    "class PtychoNN(torch.nn.Module):  \n",
    "    def __init__(self, encode_depth=2, decode_depth_1=2, decode_depth_2=2, en_filters=[], d1_filters=[], d2_filters=[]): \n",
    "        super().__init__()\n",
    "\n",
    "        #define layers in a list:\n",
    "        elayers = []\n",
    "        elayers.append(Conv2d(in_channels=1, out_channels=en_filters[0], kernel_size=3, stride=1, padding=(1,1)))\n",
    "        elayers.append(ReLU())\n",
    "        elayers = insertConv(elayers, encode_depth-1, en_filters[0], en_filters[0])\n",
    "        elayers.append(MaxPool2d((2,2)))\n",
    "        elayers = insertConv(elayers, encode_depth, en_filters[0], en_filters[1])\n",
    "        elayers.append(MaxPool2d((2,2)))\n",
    "        elayers = insertConv(elayers, encode_depth, en_filters[1], en_filters[2])\n",
    "        elayers.append(MaxPool2d((2,2)))\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(*elayers)\n",
    "        \n",
    "        \n",
    "        d1layers = []\n",
    "        d1layers = insertConv(d1layers,decode_depth_1, en_filters[2], d1_filters[0])\n",
    "        d1layers.append(Upsample(scale_factor=2, mode='bilinear'))\n",
    "        d1layers = insertConv(d1layers, decode_depth_1, d1_filters[0], d1_filters[1])\n",
    "        d1layers.append(Upsample(scale_factor=2, mode='bilinear'))\n",
    "        d1layers = insertConv(d1layers, decode_depth_1, d1_filters[1], d1_filters[2])\n",
    "        d1layers.append(Upsample(scale_factor=2, mode='bilinear'))\n",
    "        d1layers.append(Conv2d(d1_filters[2], 1, 3, stride=1, padding=(1,1)))\n",
    "        d1layers.append(torch.nn.Sigmoid())\n",
    "\n",
    "        self.decoder1 = torch.nn.Sequential(*d1layers)\n",
    "       \n",
    "\n",
    "        \n",
    "        d2layers = []\n",
    "        d2layers = insertConv(d2layers, decode_depth_2, en_filters[2], d2_filters[0])\n",
    "        d2layers.append(Upsample(scale_factor=2, mode='bilinear'))\n",
    "        d2layers = insertConv(d2layers, decode_depth_2, d2_filters[0], d2_filters[1])\n",
    "        d2layers.append(Upsample(scale_factor=2, mode='bilinear'))\n",
    "        d2layers = insertConv(d2layers, decode_depth_2, d2_filters[1], d2_filters[2])\n",
    "        d2layers.append(Upsample(scale_factor=2, mode='bilinear'))\n",
    "        d2layers.append(Conv2d(d2_filters[2], 1, 3, stride=1, padding=(1,1)))\n",
    "        d2layers.append(torch.nn.Tanh())\n",
    "\n",
    "        self.decoder2 = torch.nn.Sequential(*d2layers)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1 = self.encoder(x)\n",
    "        amp = self.decoder1(x1)\n",
    "        ph = self.decoder2(x1)\n",
    "\n",
    "        #Restore -pi to pi range\n",
    "        ph = ph*np.pi #Using tanh activation (-1 to 1) for phase so multiply by pi\n",
    "\n",
    "        return amp,ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7908ff04-5078-43f6-96d4-887487d39926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data for braggNN\n",
    "def load_data():\n",
    "\n",
    "    data_diffr = np.load('data/20191008_39_diff.npz')['arr_0']\n",
    "    real_space = np.load('data/20191008_39_amp_pha_10nm_full.npy')#, allow_pickle=True)\n",
    "    amp = np.abs(real_space)\n",
    "    ph = np.angle(real_space)\n",
    "    amp.shape\n",
    "\n",
    "\n",
    "    data_diffr = np.load('data/20191008_39_diff.npz')['arr_0']\n",
    "    real_space = np.load('data/20191008_39_amp_pha_10nm_full.npy')#, allow_pickle=True)\n",
    "    amp = np.abs(real_space)\n",
    "    ph = np.angle(real_space)\n",
    "    amp.shape\n",
    "\n",
    "    #plt.matshow(np.log10(data_diffr[0,0]))\n",
    "\n",
    "    data_diffr_red = np.zeros((data_diffr.shape[0],data_diffr.shape[1],64,64), float)\n",
    "    for i in range(data_diffr.shape[0]):\n",
    "        for j in range(data_diffr.shape[1]):\n",
    "            data_diffr_red[i,j] = resize(data_diffr[i,j,32:-32,32:-32],(64,64),preserve_range=True, anti_aliasing=True)\n",
    "            data_diffr_red[i,j] = np.where(data_diffr_red[i,j]<3,0,data_diffr_red[i,j])\n",
    "\n",
    "    tst_strt = amp.shape[0]-nltest #Where to index from\n",
    "\n",
    "    X_train = data_diffr_red[:nlines,:].reshape(-1,h,w)[:,np.newaxis,:,:]\n",
    "    X_test = data_diffr_red[tst_strt:,tst_strt:].reshape(-1,h,w)[:,np.newaxis,:,:]\n",
    "    Y_I_train = amp[:nlines,:].reshape(-1,h,w)[:,np.newaxis,:,:]\n",
    "    Y_I_test = amp[tst_strt:,tst_strt:].reshape(-1,h,w)[:,np.newaxis,:,:]\n",
    "    Y_phi_train = ph[:nlines,:].reshape(-1,h,w)[:,np.newaxis,:,:]\n",
    "    Y_phi_test = ph[tst_strt:,tst_strt:].reshape(-1,h,w)[:,np.newaxis,:,:]\n",
    "\n",
    "    ntrain = X_train.shape[0]*X_train.shape[1]\n",
    "    ntest = X_test.shape[0]*X_test.shape[1]\n",
    "\n",
    "    X_train, Y_I_train, Y_phi_train = shuffle(X_train, Y_I_train, Y_phi_train, random_state=0)\n",
    "\n",
    "    #Training data\n",
    "    X_train_tensor = torch.Tensor(X_train)\n",
    "    Y_I_train_tensor = torch.Tensor(Y_I_train)\n",
    "    Y_phi_train_tensor = torch.Tensor(Y_phi_train)\n",
    "\n",
    "    #Test data\n",
    "    X_test_tensor = torch.Tensor(X_test)\n",
    "    Y_I_test_tensor = torch.Tensor(Y_I_test)\n",
    "    Y_phi_test_tensor = torch.Tensor(Y_phi_test)\n",
    "\n",
    "    train_data = TensorDataset(X_train_tensor,Y_I_train_tensor,Y_phi_train_tensor)\n",
    "    test_data = TensorDataset(X_test_tensor)\n",
    "\n",
    "    n_train = X_train_tensor.shape[0]\n",
    "    train_data2, valid_data = torch.utils.data.random_split(train_data,[n_train-n_valid,n_valid])\n",
    "\n",
    "    #download and load training data\n",
    "    trainloader = DataLoader(train_data2, batch_size=batch, shuffle=True, num_workers=4)\n",
    "    validloader = DataLoader(valid_data, batch_size=batch, shuffle=True, num_workers=4)\n",
    "    testloader = DataLoader(test_data, batch_size=batch, shuffle=False, num_workers=4)\n",
    "\n",
    "    iterations_per_epoch = np.floor((n_train-n_valid)/batch)+1 #Final batch will be less than batch size\n",
    "    step_size = 6*iterations_per_epoch\n",
    "    return trainloader, validloader, testloader, step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebd455-531c-461b-a826-cfba41251a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the run function for the DeepHyper optimizer. \n",
    "def run(config: dict):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "    \n",
    "    metrics = {'losses':[],'val_losses':[], 'lrs':[], 'best_val_loss' : np.inf, 'best_amp_loss': np.inf, 'best_phase_loss': np.inf}\n",
    "\n",
    "    en_filters = []\n",
    "    d1_filters = []\n",
    "    d2_filters = []\n",
    "\n",
    "    en_filters.append(config[\"en1_filter\"])\n",
    "    en_filters.append(config[\"en2_filter\"])\n",
    "    en_filters.append(config[\"en3_filter\"])\n",
    "    \n",
    "    d1_filters.append(config[\"de11_filter\"])\n",
    "    d1_filters.append(config[\"de12_filter\"])\n",
    "    d1_filters.append(config[\"de13_filter\"])\n",
    "    \n",
    "    d2_filters.append(config[\"de21_filter\"])\n",
    "    d2_filters.append(config[\"de22_filter\"])\n",
    "    d2_filters.append(config[\"de23_filter\"])\n",
    "\n",
    "    edepth = config[\"edepth\"]\n",
    "    d1depth = config[\"d1depth\"]\n",
    "    d2depth = config[\"d2depth\"]\n",
    "    lrate = config[\"learning_rate\"]\n",
    "\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    embed_dim = 64\n",
    "    model = PtychoNN(encode_depth=edepth, decode_depth_1=d1depth, decode_depth_2=d2depth, en_filters=en_filters, d1_filters=d1_filters, d2_filters=d2_filters)\n",
    "\n",
    "    #summary(model,(1,64,64),device=\"cpu\")\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model) #Default all devices\n",
    "\n",
    "    model = model.to(device)\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lrate) \n",
    "\n",
    "    # load data from the DataLoader \n",
    "    # call the data loader functions directly here.\n",
    "    dl_train, dl_valid, dl_test, step_size = load_data()\n",
    "    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=lrate/10, max_lr=lrate, step_size_up=step_size, cycle_momentum=False, mode='triangular2')\n",
    "\n",
    "    #train\n",
    "    for epoch in range(epochs):\n",
    "        #iterate through all the data in the training dataset\n",
    "        tot_loss = 0.0\n",
    "        amp_loss = 0.0\n",
    "        phs_loss = 0.0\n",
    "        for i, (tr_data, tr_amp, tr_phs) in enumerate(dl_train):\n",
    "            \n",
    "            #forward pass\n",
    "            pred_amp, pred_phs = model.forward(tr_data.to(device))\n",
    "\n",
    "            #compute the individual loss for each of the functions: \n",
    "            loss_amp = loss_func(pred_amp, tr_amp.to(device))\n",
    "            loss_phs = loss_func(pred_phs, tr_phs.to(device))\n",
    "\n",
    "            #compute the total loss: \n",
    "            loss_total = loss_amp + loss_phs\n",
    "\n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            tot_loss += loss_total.detach().item()\n",
    "            amp_loss += loss_amp.detach().item()\n",
    "            phs_loss += loss_phs.detach().item()\n",
    "\n",
    "            #Update the LR according to the schedule -- CyclicLR updates each batch\n",
    "            scheduler.step()\n",
    "\n",
    "        metrics['losses'].append([tot_loss/i,amp_loss/i,phs_loss/i])\n",
    "\n",
    "        # validate\n",
    "        tot_val_loss = 0.0\n",
    "        val_loss_amp = 0.0\n",
    "        val_loss_ph = 0.0\n",
    "        \n",
    "        for j, (ft_images,amps,phs) in enumerate(dl_valid):\n",
    "        \n",
    "            ft_images = ft_images.to(device)\n",
    "            amps = amps.to(device)\n",
    "            phs = phs.to(device)\n",
    "            pred_amps, pred_phs = model(ft_images) #Forward pass\n",
    "\n",
    "            val_loss_a = loss_func(pred_amps,amps)\n",
    "            val_loss_p = loss_func(pred_phs,phs)\n",
    "            val_loss = val_loss_a + val_loss_p\n",
    "\n",
    "            tot_val_loss += val_loss.detach().item()\n",
    "            val_loss_amp += val_loss_a.detach().item()\n",
    "            val_loss_ph += val_loss_p.detach().item()\n",
    "        \n",
    "        metrics['val_losses'].append([tot_val_loss/j,val_loss_amp/j,val_loss_ph/j])\n",
    "\n",
    "        #Update the metrics for the individual phase and amplitude\n",
    "        if(val_loss_amp/j < metrics['best_amp_loss']):\n",
    "            metrics['best_amp_loss'] = val_loss_amp/j\n",
    "\n",
    "        #Update the metrics for the individual phase and amplitude\n",
    "        if(val_loss_ph/j < metrics['best_phase_loss']):\n",
    "            metrics['best_phase_loss'] = val_loss_ph/j\n",
    "\n",
    "        #Update saved model if val loss is lower\n",
    "        if(tot_val_loss/j<metrics['best_val_loss']):\n",
    "            #print(\"Saving improved model after Val Loss improved from %.5f to %.5f\" %(metrics['best_val_loss'],tot_val_loss/j))\n",
    "            metrics['best_val_loss'] = tot_val_loss/j\n",
    "    \n",
    "    print(\"Phase: %.2f, Amplitude: %.2f, Total: %.2f\" %( float(metrics['best_phase_loss']), float(metrics['best_amp_loss']), float(metrics['best_phase_loss']+metrics['best_amp_loss'])))\n",
    "    return -metrics['best_val_loss'], -pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4a2f5-5582-4c2c-b01d-f156a18f0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluator function for Deephyper\n",
    "def get_evaluator(run_function):\n",
    "    # Default arguments for Ray: 1 worker and 1 worker per evaluation\n",
    "    method_kwargs = {\n",
    "        \"num_cpus\": 1,\n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"callbacks\": [TqdmCallback()]\n",
    "    }\n",
    "\n",
    "    # If GPU devices are detected then it will create 'n_gpus' workers\n",
    "    # and use 1 worker for each evaluation\n",
    "    if is_gpu_available:\n",
    "        method_kwargs[\"num_cpus\"] = n_gpus\n",
    "        method_kwargs[\"num_gpus\"] = n_gpus\n",
    "        method_kwargs[\"num_cpus_per_task\"] = 1\n",
    "        method_kwargs[\"num_gpus_per_task\"] = 1\n",
    "\n",
    "    evaluator = Evaluator.create(\n",
    "        run_function,\n",
    "        method=\"ray\",\n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "    print(f\"Created new evaluator with {evaluator.num_workers} worker{'s' if evaluator.num_workers > 1 else ''} and config: {method_kwargs}\", )\n",
    "\n",
    "    return evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb7ba9-7da8-4ecf-b5da-c72309cbf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gpu_available = torch.cuda.is_available()\n",
    "n_gpus = torch.cuda.device_count()\n",
    "#n_gpus = 1\n",
    "\n",
    "#load data\n",
    "# hyperparameters of interest\n",
    "#1. number of neurons per layer\n",
    "#2. number of layers\n",
    "#3. learning rules\n",
    "#4. temp - slope of the discretization function\n",
    "\n",
    "problem = HpProblem()\n",
    "#epoch\n",
    "problem.add_hyperparameter((1, 100), \"epochs\", default_value=60)\n",
    "#learning rate\n",
    "problem.add_hyperparameter((0.0001, 0.1, \"log-uniform\"), \"learning_rate\", default_value=0.005)\n",
    "#encoder filter-1\n",
    "problem.add_hyperparameter((1, 256), \"en1_filter\", default_value=16)\n",
    "#encoder filter-2\n",
    "problem.add_hyperparameter((1, 256), \"en2_filter\", default_value=16)\n",
    "#encoder filter-3\n",
    "problem.add_hyperparameter((1, 256), \"en3_filter\", default_value=16)\n",
    "#decoder-1 filter-1\n",
    "problem.add_hyperparameter((1, 256), \"de11_filter\", default_value=16)\n",
    "#decoder-1 filter-2\n",
    "problem.add_hyperparameter((1, 256), \"de12_filter\", default_value=16)\n",
    "#decoder-1 filter-3\n",
    "problem.add_hyperparameter((1, 256), \"de13_filter\", default_value=16)\n",
    "#decoder-2 filter-1\n",
    "problem.add_hyperparameter((1, 256), \"de21_filter\", default_value=16)\n",
    "#decoder-2 filter-2\n",
    "problem.add_hyperparameter((1, 256), \"de22_filter\", default_value=16)\n",
    "#decoder-2 filter-3\n",
    "problem.add_hyperparameter((1, 256), \"de23_filter\", default_value=16)\n",
    "#encoder depth\n",
    "problem.add_hyperparameter((1,10), \"edepth\", default_value=2)\n",
    "#decoder-1 depth\n",
    "problem.add_hyperparameter((1,10), \"d1depth\", default_value=2)\n",
    "#decoder-2 depth\n",
    "problem.add_hyperparameter((1,10), \"d2depth\", default_value=2)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#create the evaluator\n",
    "evaluator_1 = get_evaluator(run)\n",
    "\n",
    "#trigger the search\n",
    "search = CBO(problem, evaluator_1, log_dir='./Results/')\n",
    "\n",
    "# load a surrogate\n",
    "#search.fit_surrogate(\"./Results/results1.csv\")\n",
    "\n",
    "#number of evals\n",
    "results = search.search(max_evals=numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44eeae-d3aa-41ae-8862-b6fcd70c06df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
